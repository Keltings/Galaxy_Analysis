{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17882b5a",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "The data contains 80 variables that characterize the demographic and socio-economic situation of 181\n",
    "galaxies over a period of at most 26 years. A composite index is given that measures their well-being.\n",
    "However, the demographic and socio-economic variables that influence this index is not known. We\n",
    "seek to determine, what makes the galaxies better off?\n",
    "#### We would like you to use the data and:\n",
    "1. Tell us which variables best explain the variance of the well-being index\n",
    "2. Determine the future well-being values of the galaxies\n",
    "## Submission Instructions and Format\n",
    "We have provided you data with observed values of the well-being index of each galaxy and a\n",
    "validation dataset that requires the prediction of the future well-being index.\n",
    "Kindly submit:\n",
    "1. A report that discusses the demographic and socio-economic determinants of the galaxies'\n",
    "wellbeing.\n",
    "Submission Format: The report should be a pdf of a slide presentation of not more than 5 slides\n",
    "2. The predicted future well-being index values with the highest possible level of certainty using\n",
    "data in the validation dataset.\n",
    "Submission Format: A csv file Saved as \"firstname_lastname_DSA.csv\" containing:\n",
    "Variable Description\n",
    "ID Unique identifier of the observations in the validation dataset\n",
    "Predicted Well-Being Index Prediction for the Well-Being Index\n",
    "3. Analysis file\n",
    "Submission Format: python/R notebook with detailed comments and organized analysis of EDA with\n",
    "visualizations, well documented analytical process and test results. Kindly follow reproducibility\n",
    "\n",
    "## Submission Evaluation Criteria\n",
    "The submission will be evaluation against the following criteria:\n",
    "1. The reports will be assessed on the quality of the presentation of the findings: narrative and\n",
    "visualizations\n",
    "2. The future predictions of the well-being index will be evaluated using RMSE metric\n",
    "3. . The reproducibility of your codebase\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359cfde",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#Package for graphical analysis of missingvalues\n",
    "import missingno as msno\n",
    "# Libraries for data preparation and model building\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import export_text\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b86a9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Loads a dataset from a file path using pandas library\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        The path to the dataset file\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The loaded dataset as a pandas dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set the max_columns parameter to None\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        dataset = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully from {file_path}\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset from {file_path}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0eef5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_data = load_dataset(\"datasets/Train_data.csv\")\n",
    "test_data = load_dataset(\"datasets/Validation.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b23ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def explore_dataframe(df):\n",
    "    \"\"\"\n",
    "    This function explores the data structure of a pandas dataframe\n",
    "    using various methods including df.info(), df.describe(), \n",
    "    df.nunique(), df.duplicated(), and df.isnull().sum().\n",
    "    \n",
    "    Args:\n",
    "    df (pandas.DataFrame): The dataframe to be explored.\n",
    "    \n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    print(\"DataFrame Information:\\n\")\n",
    "    df.info()\n",
    "    \n",
    "    print(\"\\n\\nDataFrame Description:\\n\")\n",
    "    print(df.describe().T)\n",
    "    \n",
    "    print(\"\\n\\nUnique Values:\\n\")\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() < 10:\n",
    "            print(col, \":\", df[col].unique())\n",
    "    \n",
    "    print(\"\\n\\nDuplicated Rows:\\n\")\n",
    "    print(df[df.duplicated()])\n",
    "    \n",
    "    print(\"\\n\\nMissing Values:\\n\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "train_data_structure = explore_dataframe(train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27372aea",
   "metadata": {},
   "source": [
    "After briefly looking through the data, notice that some entries are missing.\n",
    "\n",
    "We will determine the number of missing entries for a specified column in the dataset. We will also plot a bar graph and a matrix plot to visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1958f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def total_missing(df,column_name):\n",
    "    missing = df[column_name].isnull().sum()\n",
    "    return column_name +\" has \" + str(missing)+\" missing values\"\n",
    "\n",
    "# how many issing values for the column: Population, urban (%) \n",
    "total_missing(train_data,'Population, urban (%)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d16d4f71",
   "metadata": {},
   "source": [
    "The above column tested has more than half the data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f4750",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_missing_data(df):\n",
    "    # Create matrix plot\n",
    "    msno.matrix(df)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create bar plot\n",
    "    msno.bar(df)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52d32ac2",
   "metadata": {},
   "source": [
    "It would be a good idea to replace some of the missing data. Missing values can be replaced with the either the mean , the median or the mode (in the case of categorical columns). However, based on the data we have columns that have extremely high percentage of missing values(more than half of the records). I might drop sme of the columns to avoid bias when training our set for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c854ab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def drop_missing_columns(df, n):\n",
    "    \"\"\"\n",
    "    Drops columns with too many missing values from a DataFrame and prints\n",
    "    the resulting information about the DataFrame.\n",
    "    \n",
    "    Arguments:\n",
    "    train_data -- pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Compute the threshold for dropping columns\n",
    "    threshold = df.shape[0] - n\n",
    "    \n",
    "    # Drop columns with too many missing values\n",
    "    df.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "    \n",
    "    # Print the information about the resulting DataFrame\n",
    "    print(df.info())\n",
    "\n",
    "clean_train_df = train_data.copy() \n",
    "drop_missing_columns(clean_train_df,1000)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916fff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plot_missing_data(clean_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ce832",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def impute_missing_values(df, impute_method):\n",
    "    '''\n",
    "    Imputes missing values in a DataFrame using mean, mode, or median for each column.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame containing missing values\n",
    "        impute_method (str): 'mean', 'mode', or 'median'\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with imputed values\n",
    "    '''\n",
    "    if impute_method not in ['mean', 'mode', 'median']:\n",
    "        raise ValueError(\"impute_method must be 'mean', 'mode', or 'median'\")\n",
    "    \n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    # Loop over columns with missing values and impute based on the specified method\n",
    "    for col in df_imputed.columns[df_imputed.isnull().any()]:\n",
    "        if impute_method == 'mean':\n",
    "            df_imputed[col].fillna(df_imputed[col].mean(), inplace=True)\n",
    "        elif impute_method == 'mode':\n",
    "            df_imputed[col].fillna(df_imputed[col].mode()[0], inplace=True)\n",
    "        elif impute_method == 'median':\n",
    "            df_imputed[col].fillna(df_imputed[col].median(), inplace=True)\n",
    "    \n",
    "    return df_imputed\n",
    "\n",
    "median_imputed_df = impute_missing_values(clean_train_df, 'median')\n",
    "median_imputed_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb6b4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_numeric_histograms(df):\n",
    "    num_cols = list(df.select_dtypes(include=['float64', 'int64']).columns)\n",
    "    df[num_cols].plot(kind='density', subplots=True, layout=(4, 3), sharex=False, figsize=(20, 15))\n",
    "    df[num_cols].hist(figsize=(20,15))\n",
    "\n",
    "plot_numeric_histograms(median_imputed_df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf9ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_boxplot(df):\n",
    "    num_cols = len(df.select_dtypes(include=['float64', 'int64']).columns)\n",
    "    num_col_list = list(df.select_dtypes(include=['float64', 'int64']).columns)\n",
    "    fig, axs = plt.subplots(nrows=4, ncols=3, figsize=(12, 16))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, col in enumerate(num_col_list):\n",
    "        if i < 12: # Only plot the first 12 numerical columns\n",
    "            sns.boxplot(data=df[col], ax=axs[i])\n",
    "            axs[i].set_title(col)\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for i in range(num_cols, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "plot_boxplot(median_imputed_df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20350b34",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def relationship(df):\n",
    "    sns.set_style()\n",
    "    num_col_list = list(df.select_dtypes(include=['float64', 'int64']).columns)\n",
    "    heatmap = sns.heatmap(df[num_col_list].corr(), vmin=-1, vmax=1, annot=True)\n",
    "    heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':10}, pad=12)\n",
    "\n",
    "relationship(median_imputed_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91b698",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_pairplot(df):\n",
    "    \"\"\"\n",
    "    Plots a pairplot for a pandas DataFrame using the Seaborn library.\n",
    "    \n",
    "    Arguments:\n",
    "    data -- pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create a pairplot using the Seaborn library\n",
    "    sns.pairplot(df, size=2, corner=True)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_pairplot(median_imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9baa3e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def scale_dataframe_robust(df):\n",
    "    \"\"\"\n",
    "    Scales the columns of a pandas DataFrame using the RobustScaler from the Scikit-learn library.\n",
    "    \n",
    "    Arguments:\n",
    "    data -- pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    scaled_data -- pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Create a RobustScaler object\n",
    "    scaler = RobustScaler()\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    \n",
    "    # Convert the scaled data to a DataFrame\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "    \n",
    "    # Return the scaled data\n",
    "    return scaled_data\n",
    "\n",
    "df  = median_imputed_df.drop('galaxy', axis=1)\n",
    "scaled_df = scale_dataframe_robust(df)\n",
    "scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273344c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X = scaled_df.drop(\"Well-Being Index\", axis=1).values\n",
    "y = scaled_df[\"Well-Being Index\"].values\n",
    "print(type(X), type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03855a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_actual_vs_predicted(model, X, y):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the specified model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse_score = mse(y_test, y_pred)\n",
    "    \n",
    "    # Print the mean squared error and return the trained model\n",
    "    print(f\"Mean squared error: {mse_score:.2f}\")\n",
    "    print(np.sqrt(mse_score))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"R2:\", r2)\n",
    "\n",
    "    # Plot the actual vs predicted values\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.xlabel('Actual Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "    plt.title('Actual vs Predicted Values')\n",
    "    \n",
    "    # Overlay the regression line\n",
    "    z = np.polyfit(y_test, y_pred, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(y_test, p(y_test), color='magenta')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a2c99",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plot_actual_vs_predicted(LinearRegression(),X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab7e61",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plot_actual_vs_predicted(DecisionTreeRegressor(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756e73e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "plot_actual_vs_predicted(DecisionTreeRegressor(),X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbdf19",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plot_actual_vs_predicted(GradientBoostingRegressor(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349dfc3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "plot_actual_vs_predicted(GradientBoostingRegressor(),X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cd3ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78172089",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "# configure to select all features\n",
    "best_features = SelectKBest(score_func=f_regression, k='all')\n",
    "# learn relationship from training data\n",
    "best_features.fit(X_train, y_train)\n",
    "# transform train input data\n",
    "X_train_best_features = best_features.transform(X_train)\n",
    "# transform test input data\n",
    "X_test_best_features = best_features.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f3903",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i in range(len(best_features.scores_)):\n",
    "    print('Feature %d: %f' % (i, best_features.scores_[i]))\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(best_features.scores_))], best_features.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda76eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def cross_validate_models(model, X, y):\n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kf)\n",
    "    print(f\"CV results: {cv_results.mean():.3f} (+/- {cv_results.std():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49959e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cross_validate_models(DecisionTreeRegressor(random_state=42), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd06d32e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {\"alpha\": np.arange(0.0001, 1, 10),\"solver\": [\"sag\", \"lsqr\"]}\n",
    "ridge = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=kf)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "print(ridge_cv.best_params_, ridge_cv.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843a505",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {'alpha': np.arange(0.0001, 1, 10)}\n",
    "grad = GradientBoostingRegressor()\n",
    "grad_cv = RandomizedSearchCV(grad, param_grid, cv=kf, n_iter=2)\n",
    "grad_cv.fit(X_train, y_train)\n",
    "print(grad_cv.best_params_, grad_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57adfa4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#evaluating on the test set\n",
    "test_score = grad_cv.score(X_test, y_test)\n",
    "print(test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0dc05b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X = scaled_df.drop(\"Well-Being Index\", axis=1).values\n",
    "y = scaled_df['Well-Being Index'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "# evaluating regression models\n",
    "models = {\"Linear Regression\": RandomForestRegressor(), \"Gradient Boost\": GradientBoostingRegressor(), \"Decision Tree\": DecisionTreeRegressor()}\n",
    "results = []\n",
    "for model in models.values():     \n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)     \n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kf)     \n",
    "    results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5003922e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for name, model in models.items():  \n",
    "    model.fit(X_train, y_train)  \n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print(\"{} Test Set Accuracy: {}\".format(name, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d3208",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
